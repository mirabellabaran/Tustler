using Microsoft.VisualStudio.TestTools.UnitTesting;
using System.Linq;
using TustlerServicesLib;

namespace TustlerServicesLibTest
{
    [TestClass]
    public class SentenceChunkerTester
    {
        readonly string testString = @"A de?ning feature of polychronous groups is that the connected chain of sub-graphs that distinguishes the group has the potential to sustain a causal cascade of neural ?ring. Activation of a PNG produces polychronization, a reproducible and precisely timed sequence of ?ring events that is observable in the ?ring data generated by the network (Izhikevich et al., 2004, Izhikevich, 2006a). Unlike the ?ring sequences generated by a syn?re chain, the ?ring sequences generated by polychronization are not synchronous but polychronous (literally many times) i.e. although precisely timed, they occur over a range of di?erent times. Syn?re chains and polychronous groups therefore di?er in their synchronization dependencies, although some researchers have attempted to reconcile the two research areas by referring to an alternative type of syn?re chain called a syn?re braid. While syn?re chains have connections of constant length between pools, the connections between synchronous ?ring pools in a syn?re braid have variable conduction delays that are capable of polychronization (Bienenstock, 1995). Importantly, the spatio-temporal nature of polychronicity allows polychronous groups to enjoy a kind of time-sharing arrangement with respect to their constituent neurons i.e. the involvement of each neuron in binding a group is restricted to only small slices of time, allowing the neuron to participate in multiple groups. The e?ect is that the number of polychronous groups in a network grows faster than the number of neurons. Indeed, large networks can theoretically contain more PNGs than neurons (Izhikevich, 2006a), an important property that is of particular relevance to the capacity of a system of representation based on polychronicity. It is important to distinguish between polychronous groups that exist within the connection structure of a network (i.e. structural PNGs), and the spatio-temporal ?ring sequences that are indicative of the activation of structural PNGs (i.e. activated PNGs). Structural PNGs provide the spatio-temporal template that de?nes this pattern of activation. However, while all structural PNGs are theoretically capable of generating these polychronous ?ring sequences, they may ?rst require adaptation in order to do so (see next section).
For structural PNGs, the ?ring events that de?ne the group are purely theoretical, while for activated PNGs the group ?ring events can be ?ltered from the network ?ring data. In addition, two types of structural PNGs have been de?ned: supported groups are those with the requisite convergent structure to support a graph-theoretical version of polychronization that is independent of the synaptic connection weights in the network; in contrast, adapted groups have additional adaptations that allow polychronization in more realistic network models that incorporate synaptic weights. Although supported groups provide the necessary convergence to support polychronization, the polychronous groups in biological networks are assumed to also require strong connections between group members in order to sustain ?ring activity across the group. Thus, supported PNGs are de?ned in terms of network connectivity alone while adapted groups must also take synaptic weights into account (Martinez and Paugam-Moisy, 2009).
Supported and adapted polychronous groups are assumed to co-exist in a dynamic equilibrium that is sensitive to the network inputs (Izhikevich, 2006a). An unsupervised learning rule governs this dynamic equilibrium, selectively reinforcing supported groups that best match the current inputs and weakening connections with non-matching conduction delays. The e?ect of the learning rule is a selective adaptation of connection weights in a way that supports the propagation of ?ring activity within each matching group. However, some degree of adaptation seems to occur even in the absence of structured input, as is the case in model networks exposed to random input. Under these conditions the network connection weights adapt to the underlying connection structure of the network, reinforcing only those groups whose conduction delays match the network dynamics. This process of network maturation is often exploited in model networks where the initialization of synaptic weights to random values (or often a constant value) means that adapted PNGs are unlikely to occur.
Selective reinforcement of supported groups requires a learning rule that is sensitive to both the precise timing and the temporal order of ?ring events. A sensitivity to precise timing allows the selective reinforcement of connections whose conduction delays match the ?ring times of the pre-synaptic and post-synaptic neurons, while a sensitivity to temporal order supports a Hebbian notion of causality in which the e?ciency of one neuron in contributing to the ?ring of another is increased. One well-known and empirically supported learning rule that meets these criteria is spike-timing-dependent plasticity (or STDP) (Gerstner et al., 1993, 1996, Markram et al., 1997, Caporale and Dan, 2008). It is an unsupervised local learning rule that operates at the local level of each connection, without bene?t of an error or reward signal. It also closely matches the temporally sensitive learning rule that Donald Hebb seemed to have in mind, producing the much quoted e?ect of: neurons that ?re together, wire together (Shatz, 1996). However, it has an additional feature in that the magnitude of synaptic change (i.e. the strength of the resulting wiring) is sensitive to the precise timing of each neural spike.";

        [TestMethod]
        public void TestChunkSize5000Returns1Chunk()
        {
            var chunker = new TustlerServicesLib.SentenceChunker(testString, 5000);
            Assert.AreEqual(chunker.NumChunks, 2);
        }

        [TestMethod]
        public void TestChunkSize300Returns10Chunks()
        {
            var chunker = new TustlerServicesLib.SentenceChunker(testString, 300);
            Assert.AreEqual(chunker.NumChunks, 26);

            var terminators = new[] { '.', '!', '?' };
            var allSentencesEndInTerminators = chunker.Chunks.All(kvp => terminators.Contains(kvp.Value.Last()));
            Assert.IsTrue(allSentencesEndInTerminators);
        }
    }
}
